{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import CompressionLayer, QuantizationLayer, FeatureSelectionLayer, HardQuantizationLayer, HardQuantizationThresholdLayer\n",
    "from models import MultiLayerPerceptron\n",
    "from datasets import get_dataloader\n",
    "from training_utils import train_model, eval_val, eval_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'California_Housing'\n",
    "train_loader, val_loader, test_loader = get_dataloader(dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_quantile(train_loader, quantiles):\n",
    "    all_data = []\n",
    "\n",
    "    # Collect all data from the train_loader\n",
    "    for batch in train_loader:\n",
    "        inputs, _ = batch\n",
    "        all_data.append(inputs)\n",
    "\n",
    "    # Concatenate all data along the first dimension\n",
    "    all_data = torch.cat(all_data, dim=0)\n",
    "    quantile_values = torch.quantile(all_data, quantiles, dim=0).transpose(0,1)\n",
    "    return quantile_values\n",
    "\n",
    "def get_quantization_thresholds(train_loader, n_bits):\n",
    "    thresholds = 2 ** n_bits - 1\n",
    "    quantiles = torch.arange(1 / (thresholds + 1), 1, 1 / (thresholds + 1))\n",
    "    thresholds = estimate_quantile(train_loader, quantiles)\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [8,128,128,128,1]\n",
    "thresholds = get_quantization_thresholds(train_loader, n_bits=2)\n",
    "model = HardQuantizationThresholdLayer(thresholds=thresholds)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "inputs, targets = data\n",
    "output = model(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = [128, 256, 512, 1024]\n",
    "max_hidden_layers = 6\n",
    "neuron_combinations = [[hidden_neuron] for hidden_neuron in hidden_neurons]\n",
    "neuron_combination_dict = {1: neuron_combinations}\n",
    "neuron_combinations = []\n",
    "for current_layers in range(2,max_hidden_layers + 1):\n",
    "    current_lists = neuron_combination_dict.get(current_layers-1)\n",
    "    new_lists = []\n",
    "    for current_list in current_lists:\n",
    "        for hidden_neuron in hidden_neurons:\n",
    "            new_list = current_list + [hidden_neuron]\n",
    "            ## Only add new_list, if it first goes up in neurons and then down\n",
    "            # if (np.diff(np.sign(np.diff(np.array(new_list)))) <= 0).all() & np.count_nonzero(np.diff(np.sign(np.diff(np.array(new_list))))) <=1:\n",
    "            ## Only add new_list, if it first goes up in neurons and then down and only has 2 values    \n",
    "            if ((np.diff(np.sign(np.diff(np.array(new_list)))) <= 0).all()) & (np.count_nonzero(np.diff(np.sign(np.diff(np.array(new_list))))) <=2) & (len(np.unique(np.array(new_list))) <= 3):\n",
    "                new_lists.append(new_list)\n",
    "    neuron_combination_dict.update({current_layers: new_lists})\n",
    "    if current_layers > 3:\n",
    "        neuron_combinations += new_lists\n",
    "\n",
    "print(len(neuron_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_hard_quantization_threshold(n_steps = 10, n_bits =8, optimize_dict = {}, device = 'cpu', when = 'pre'):\n",
    "    thresholds = get_quantization_thresholds(train_loader, n_bits)\n",
    "\n",
    "    # Define default hyperparameters\n",
    "    weight_decay =  0\n",
    "    learning_rate = 0.001\n",
    "    neuron_combination = [256,256]\n",
    "    num_epochs = 30\n",
    "    add_noise = False\n",
    "\n",
    "    # Lists to store results\n",
    "    random_search_losses = []\n",
    "    hyperparameter_dict = {\n",
    "        'weight_decay': [],\n",
    "        'learning_rate': [],\n",
    "        'architecture': [],\n",
    "        'num_epochs': [],\n",
    "        'add_noise': []}\n",
    "    \n",
    "\n",
    "    # Perform random search\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        for key, value in optimize_dict.items():\n",
    "            if key == 'weight_decay':\n",
    "                weight_decay = random.choice(value)\n",
    "            elif key == 'learning_rate':\n",
    "                learning_rate = random.choice(value)\n",
    "            elif key == 'neuron_combination':\n",
    "                neuron_combination = random.choice(value)\n",
    "            elif key == 'num_epochs':\n",
    "                num_epochs = random.choice(value)    \n",
    "            elif key == 'add_noise':\n",
    "                add_noise = random.choice(value)    \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown hyperparameter: {key}\")\n",
    "            \n",
    "        architecture = [8] + neuron_combination + [1]\n",
    "        hyperparameter_dict['weight_decay'].append(weight_decay)\n",
    "        hyperparameter_dict['learning_rate'].append(learning_rate)\n",
    "        hyperparameter_dict['architecture'].append(neuron_combination)\n",
    "        hyperparameter_dict['num_epochs'].append(num_epochs)\n",
    "        hyperparameter_dict['add_noise'].append(add_noise)\n",
    "\n",
    "        quantization_model = HardQuantizationThresholdLayer(thresholds=thresholds)\n",
    "        mlp = MultiLayerPerceptron(architecture)\n",
    "\n",
    "        if when == 'pre':\n",
    "            training_model = nn.Sequential(\n",
    "                quantization_model,\n",
    "                mlp\n",
    "            )\n",
    "        elif when == 'post':\n",
    "            training_model = mlp\n",
    "\n",
    "        eval_model = nn.Sequential(\n",
    "                quantization_model,\n",
    "                mlp\n",
    "            )\n",
    "        \n",
    "\n",
    "        training_model.to(device)\n",
    "        eval_model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(training_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        best_val_loss = train_model(training_model, num_epochs=num_epochs,\n",
    "                    train_loader=train_loader, test_loader=test_loader,\n",
    "                    optimizer=optimizer, criterion=criterion, has_quantization_layer=False,\n",
    "                    train_quantization_layer=False, print_result=False,\n",
    "                    add_noise=add_noise, device=device)\n",
    "\n",
    "        val_loss = eval_val(model=eval_model,\n",
    "                val_dataloader=test_loader,\n",
    "                criterion=criterion, device = device)\n",
    "        \n",
    "        if when == 'pre':\n",
    "            random_search_losses.append(best_val_loss)\n",
    "        elif when == 'post':\n",
    "            random_search_losses.append(val_loss)    \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Architecture': hyperparameter_dict['architecture'],\n",
    "        'Loss': random_search_losses,\n",
    "        'Weight Decay': hyperparameter_dict['weight_decay'],\n",
    "        'Learning Rate': hyperparameter_dict['learning_rate'],\n",
    "        'Num Epochs': hyperparameter_dict['num_epochs'],\n",
    "        'Add Noise': hyperparameter_dict['add_noise']\n",
    "\n",
    "    })\n",
    "    results_df = results_df.sort_values('Loss')  # Sort by loss ascending    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [16:58<00:00, 20.37s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df_pre = random_search_hard_quantization_threshold( n_bits = 8,\n",
    "                                              n_steps = 50,\n",
    "                                              optimize_dict=\n",
    "                                              {'weight_decay': [0, 0.0001],\n",
    "                                              'learning_rate': [0.001, 0.0001],\n",
    "                                                'add_noise': [False, True],\n",
    "                                              'neuron_combination': neuron_combinations,\n",
    "                                              'num_epochs': [30]},\n",
    "                                              device = device,\n",
    "                                              when = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Architecture",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight Decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Learning Rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Num Epochs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Add Noise",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ea0cbd94-89d7-46a6-bd2c-925c04d58dd9",
       "rows": [
        [
         "32",
         "[128, 512, 512, 512, 512, 128]",
         "0.32080910824812375",
         "0.0",
         "0.001",
         "30",
         "False"
        ],
        [
         "2",
         "[128, 128, 128, 128, 128, 128]",
         "0.3220911482205758",
         "0.0001",
         "0.001",
         "30",
         "False"
        ],
        [
         "22",
         "[128, 256, 1024, 1024, 1024, 1024]",
         "0.32554974349645466",
         "0.0001",
         "0.001",
         "30",
         "False"
        ],
        [
         "43",
         "[128, 256, 256, 256, 128]",
         "0.331088069998301",
         "0.0001",
         "0.001",
         "30",
         "True"
        ],
        [
         "42",
         "[512, 512, 512, 512, 128]",
         "0.33627402369792647",
         "0.0",
         "0.001",
         "30",
         "False"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Num Epochs</th>\n",
       "      <th>Add Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[128, 512, 512, 512, 512, 128]</td>\n",
       "      <td>0.320809</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[128, 128, 128, 128, 128, 128]</td>\n",
       "      <td>0.322091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[128, 256, 1024, 1024, 1024, 1024]</td>\n",
       "      <td>0.325550</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[128, 256, 256, 256, 128]</td>\n",
       "      <td>0.331088</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[512, 512, 512, 512, 128]</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Architecture      Loss  Weight Decay  Learning Rate  \\\n",
       "32      [128, 512, 512, 512, 512, 128]  0.320809        0.0000          0.001   \n",
       "2       [128, 128, 128, 128, 128, 128]  0.322091        0.0001          0.001   \n",
       "22  [128, 256, 1024, 1024, 1024, 1024]  0.325550        0.0001          0.001   \n",
       "43           [128, 256, 256, 256, 128]  0.331088        0.0001          0.001   \n",
       "42           [512, 512, 512, 512, 128]  0.336274        0.0000          0.001   \n",
       "\n",
       "    Num Epochs  Add Noise  \n",
       "32          30      False  \n",
       "2           30      False  \n",
       "22          30      False  \n",
       "43          30       True  \n",
       "42          30      False  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_pre.to_csv(f'results/{dataset}/random_search_results_hard_quantization_quantiles_pre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results_df_post = random_search_hard_quantization_threshold( n_bits = 8,\n",
    "                                              n_steps = 50,\n",
    "                                              optimize_dict=\n",
    "                                              {'weight_decay': [0, 0.0001],\n",
    "                                              'learning_rate': [0.001, 0.0001],\n",
    "                                                'add_noise': [False, True],\n",
    "                                              'neuron_combination': neuron_combinations,\n",
    "                                              'num_epochs': [30]},\n",
    "                                              device = device,\n",
    "                                              when = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Architecture",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight Decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Learning Rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Num Epochs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Add Noise",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "77de5bb4-d874-4185-85ea-38c828a1a6c6",
       "rows": [
        [
         "30",
         "[1024, 1024, 1024, 1024, 1024, 1024]",
         "3.0180739366091216",
         "0.0001",
         "0.001",
         "30",
         "False"
        ],
        [
         "2",
         "[256, 512, 1024, 1024, 1024, 512]",
         "3.307788507754986",
         "0.0",
         "0.001",
         "30",
         "False"
        ],
        [
         "5",
         "[128, 256, 1024, 1024, 1024, 1024]",
         "5.495317847912128",
         "0.0001",
         "0.001",
         "30",
         "False"
        ],
        [
         "27",
         "[128, 512, 512, 512, 256]",
         "5.691167229872484",
         "0.0001",
         "0.001",
         "30",
         "False"
        ],
        [
         "10",
         "[256, 512, 512, 512, 128]",
         "7.217901552640475",
         "0.0001",
         "0.001",
         "30",
         "False"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Num Epochs</th>\n",
       "      <th>Add Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[1024, 1024, 1024, 1024, 1024, 1024]</td>\n",
       "      <td>3.018074</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[256, 512, 1024, 1024, 1024, 512]</td>\n",
       "      <td>3.307789</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[128, 256, 1024, 1024, 1024, 1024]</td>\n",
       "      <td>5.495318</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[128, 512, 512, 512, 256]</td>\n",
       "      <td>5.691167</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[256, 512, 512, 512, 128]</td>\n",
       "      <td>7.217902</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Architecture      Loss  Weight Decay  \\\n",
       "30  [1024, 1024, 1024, 1024, 1024, 1024]  3.018074        0.0001   \n",
       "2      [256, 512, 1024, 1024, 1024, 512]  3.307789        0.0000   \n",
       "5     [128, 256, 1024, 1024, 1024, 1024]  5.495318        0.0001   \n",
       "27             [128, 512, 512, 512, 256]  5.691167        0.0001   \n",
       "10             [256, 512, 512, 512, 128]  7.217902        0.0001   \n",
       "\n",
       "    Learning Rate  Num Epochs  Add Noise  \n",
       "30          0.001          30      False  \n",
       "2           0.001          30      False  \n",
       "5           0.001          30      False  \n",
       "27          0.001          30      False  \n",
       "10          0.001          30      False  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_post.to_csv(f'results/{dataset}/random_search_results_hard_quantization_quantiles_post.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
