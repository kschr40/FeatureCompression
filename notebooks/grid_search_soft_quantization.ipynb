{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import CompressionLayer, QuantizationLayer, FeatureSelectionLayer, HardQuantizationLayer, HardQuantizationThresholdLayer\n",
    "from models import MultiLayerPerceptron\n",
    "from datasets import get_dataloader\n",
    "from training_utils import train_model, eval_val, eval_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'California_Housing'\n",
    "train_loader, val_loader, test_loader = get_dataloader(dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_quantile(train_loader, quantiles):\n",
    "    all_data = []\n",
    "\n",
    "    # Collect all data from the train_loader\n",
    "    for batch in train_loader:\n",
    "        inputs, _ = batch\n",
    "        all_data.append(inputs)\n",
    "\n",
    "    # Concatenate all data along the first dimension\n",
    "    all_data = torch.cat(all_data, dim=0)\n",
    "    quantile_values = torch.quantile(all_data, quantiles, dim=0).transpose(0,1)\n",
    "    return quantile_values\n",
    "\n",
    "def get_quantization_thresholds(train_loader, n_bits):\n",
    "    thresholds = 2 ** n_bits - 1\n",
    "    quantiles = torch.arange(1 / (thresholds + 1), 1, 1 / (thresholds + 1))\n",
    "    thresholds = estimate_quantile(train_loader, quantiles)\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for DNN with SoftQuantizationLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = [128, 256, 512, 1024]\n",
    "max_hidden_layers = 6\n",
    "neuron_combinations = [[hidden_neuron] for hidden_neuron in hidden_neurons]\n",
    "neuron_combination_dict = {1: neuron_combinations}\n",
    "neuron_combinations = []\n",
    "for current_layers in range(2,max_hidden_layers + 1):\n",
    "    current_lists = neuron_combination_dict.get(current_layers-1)\n",
    "    new_lists = []\n",
    "    for current_list in current_lists:\n",
    "        for hidden_neuron in hidden_neurons:\n",
    "            new_list = current_list + [hidden_neuron]\n",
    "            ## Only add new_list, if it first goes up in neurons and then down\n",
    "            # if (np.diff(np.sign(np.diff(np.array(new_list)))) <= 0).all() & np.count_nonzero(np.diff(np.sign(np.diff(np.array(new_list))))) <=1:\n",
    "            ## Only add new_list, if it first goes up in neurons and then down and only has 2 values    \n",
    "            if ((np.diff(np.sign(np.diff(np.array(new_list)))) <= 0).all()) & (np.count_nonzero(np.diff(np.sign(np.diff(np.array(new_list))))) <=2) & (len(np.unique(np.array(new_list))) <= 3):\n",
    "                new_lists.append(new_list)\n",
    "    neuron_combination_dict.update({current_layers: new_lists})\n",
    "    if current_layers > 3:\n",
    "        neuron_combinations += new_lists\n",
    "\n",
    "print(len(neuron_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_soft_quantization_threshold(n_steps = 10, n_bits =8, optimize_dict = {}, device = 'cpu'):\n",
    "    thresholds = get_quantization_thresholds(train_loader, n_bits)\n",
    "\n",
    "    # Define default hyperparameters\n",
    "    weight_decay =  0\n",
    "    learning_rate = 0.001\n",
    "    neuron_combination = [256,256]\n",
    "    num_epochs = 30\n",
    "    add_noise = False\n",
    "    decrease_factor = 0.001\n",
    "\n",
    "    # Lists to store results\n",
    "    random_search_losses = []\n",
    "    hyperparameter_dict = {\n",
    "        'weight_decay': [],\n",
    "        'learning_rate': [],\n",
    "        'architecture': [],\n",
    "        'num_epochs': [],\n",
    "        'add_noise': [],\n",
    "        'decrease_factor': []}\n",
    "    \n",
    "\n",
    "    # Perform random search\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        for key, value in optimize_dict.items():\n",
    "            if key == 'weight_decay':\n",
    "                weight_decay = random.choice(value)\n",
    "            elif key == 'learning_rate':\n",
    "                learning_rate = random.choice(value)\n",
    "            elif key == 'neuron_combination':\n",
    "                neuron_combination = random.choice(value)\n",
    "            elif key == 'num_epochs':\n",
    "                num_epochs = random.choice(value)    \n",
    "            elif key == 'add_noise':\n",
    "                add_noise = random.choice(value)    \n",
    "            elif key == 'decrease_factor':\n",
    "                decrease_factor = random.choice(value)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown hyperparameter: {key}\")\n",
    "            \n",
    "        architecture = [8] + neuron_combination + [1]\n",
    "        hyperparameter_dict['weight_decay'].append(weight_decay)\n",
    "        hyperparameter_dict['learning_rate'].append(learning_rate)\n",
    "        hyperparameter_dict['architecture'].append(neuron_combination)\n",
    "        hyperparameter_dict['num_epochs'].append(num_epochs)\n",
    "        hyperparameter_dict['add_noise'].append(add_noise)\n",
    "\n",
    "        quantization_model = QuantizationLayer(num_features = thresholds.shape[0], num_thresholds_per_feature=thresholds.shape[1],tau = 1)\n",
    "        quantization_model.set_thresholds(thresholds)\n",
    "        mlp = MultiLayerPerceptron(architecture)\n",
    "        model = nn.Sequential(\n",
    "            quantization_model,\n",
    "            mlp\n",
    "        )\n",
    "        \n",
    "\n",
    "        model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        best_val_loss = train_model(model, num_epochs=num_epochs,\n",
    "                    train_loader=train_loader, test_loader=test_loader, decrease_factor=decrease_factor,\n",
    "                    optimizer=optimizer, criterion=criterion, has_quantization_layer=True,\n",
    "                    train_quantization_layer=True, print_result=False,\n",
    "                    add_noise=add_noise, device=device)\n",
    "\n",
    "        val_loss = eval_val(model=model,\n",
    "                val_dataloader=test_loader,\n",
    "                criterion=criterion, device = device)\n",
    "        \n",
    "        random_search_losses.append(best_val_loss)\n",
    " \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Architecture': hyperparameter_dict['architecture'],\n",
    "        'Loss': random_search_losses,\n",
    "        'Weight Decay': hyperparameter_dict['weight_decay'],\n",
    "        'Learning Rate': hyperparameter_dict['learning_rate'],\n",
    "        'Num Epochs': hyperparameter_dict['num_epochs'],\n",
    "        'Add Noise': hyperparameter_dict['add_noise'],\n",
    "        'Decrease Factor': hyperparameter_dict['decrease_factor']\n",
    "    })\n",
    "    results_df = results_df.sort_values('Loss')  # Sort by loss ascending    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [52:25<00:00, 20.97s/it] \n"
     ]
    }
   ],
   "source": [
    "results_df_soft = random_search_soft_quantization_threshold( n_bits = 8,\n",
    "                                              n_steps = 150,\n",
    "                                              optimize_dict=\n",
    "                                              {'weight_decay': [0, 0.0001],\n",
    "                                              'learning_rate': [0.001, 0.0001],\n",
    "                                              'add_noise': [False, True],\n",
    "                                              'neuron_combination': neuron_combinations,\n",
    "                                              'num_epochs': [10,30,50],\n",
    "                                              'decrease_factor': [0.001, 0.0001]},\n",
    "                                              device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Num Epochs</th>\n",
       "      <th>Add Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[128, 256, 256, 256, 128]</td>\n",
       "      <td>0.266940</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[1024, 1024, 1024, 1024, 1024, 1024]</td>\n",
       "      <td>0.273487</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[512, 1024, 1024, 1024, 1024, 256]</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[256, 1024, 1024, 1024, 1024, 256]</td>\n",
       "      <td>0.276937</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[128, 512, 1024, 1024, 1024, 512]</td>\n",
       "      <td>0.276987</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Architecture      Loss  Weight Decay  \\\n",
       "87             [128, 256, 256, 256, 128]  0.266940        0.0000   \n",
       "98  [1024, 1024, 1024, 1024, 1024, 1024]  0.273487        0.0000   \n",
       "41    [512, 1024, 1024, 1024, 1024, 256]  0.275008        0.0001   \n",
       "32    [256, 1024, 1024, 1024, 1024, 256]  0.276937        0.0000   \n",
       "86     [128, 512, 1024, 1024, 1024, 512]  0.276987        0.0001   \n",
       "\n",
       "    Learning Rate  Num Epochs  Add Noise  \n",
       "87          0.001          50      False  \n",
       "98          0.001          50      False  \n",
       "41          0.001          50      False  \n",
       "32          0.001          50      False  \n",
       "86          0.001          50      False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_soft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_soft.to_csv(f'results/{dataset}/random_search_results_soft_quantization.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for DNN with SoftCompressionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_soft_compression_threshold(n_steps = 10, n_bits =8, optimize_dict = {}, device = 'cpu'):\n",
    "    thresholds = get_quantization_thresholds(train_loader, n_bits)\n",
    "\n",
    "    # Define default hyperparameters\n",
    "    weight_decay =  0\n",
    "    learning_rate = 0.001\n",
    "    neuron_combination = [256,256]\n",
    "    num_epochs = 30\n",
    "    add_noise = False\n",
    "    decrease_factor = 0.001\n",
    "\n",
    "    # Lists to store results\n",
    "    random_search_losses = []\n",
    "    hyperparameter_dict = {\n",
    "        'weight_decay': [],\n",
    "        'learning_rate': [],\n",
    "        'architecture': [],\n",
    "        'num_epochs': [],\n",
    "        'add_noise': [],\n",
    "        'decrease_factor': []}\n",
    "    \n",
    "\n",
    "    # Perform random search\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        for key, value in optimize_dict.items():\n",
    "            if key == 'weight_decay':\n",
    "                weight_decay = random.choice(value)\n",
    "            elif key == 'learning_rate':\n",
    "                learning_rate = random.choice(value)\n",
    "            elif key == 'neuron_combination':\n",
    "                neuron_combination = random.choice(value)\n",
    "            elif key == 'num_epochs':\n",
    "                num_epochs = random.choice(value)    \n",
    "            elif key == 'add_noise':\n",
    "                add_noise = random.choice(value)    \n",
    "            elif key == 'decrease_factor':\n",
    "                decrease_factor = random.choice(value)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown hyperparameter: {key}\")\n",
    "            \n",
    "        architecture = [(2**8-1)*8] + neuron_combination + [1]\n",
    "        hyperparameter_dict['weight_decay'].append(weight_decay)\n",
    "        hyperparameter_dict['learning_rate'].append(learning_rate)\n",
    "        hyperparameter_dict['architecture'].append(neuron_combination)\n",
    "        hyperparameter_dict['num_epochs'].append(num_epochs)\n",
    "        hyperparameter_dict['add_noise'].append(add_noise)\n",
    "        hyperparameter_dict['decrease_factor'].append(decrease_factor)\n",
    "\n",
    "        quantization_model = CompressionLayer(a_init = thresholds.flatten(), a_index = torch.repeat_interleave(torch.arange(8),2**8-1), tau = 1)\n",
    "        # CompressionLayer(num_features = thresholds.shape[0], num_thresholds_per_feature=thresholds.shape[1],tau = 1)\n",
    "        # quantization_model.set_thresholds(thresholds)\n",
    "        mlp = MultiLayerPerceptron(architecture)\n",
    "        model = nn.Sequential(\n",
    "            quantization_model,\n",
    "            mlp\n",
    "        )\n",
    "        \n",
    "\n",
    "        model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        best_val_loss = train_model(model, num_epochs=num_epochs,\n",
    "                    train_loader=train_loader, test_loader=test_loader, decrease_factor=decrease_factor,\n",
    "                    optimizer=optimizer, criterion=criterion, has_quantization_layer=True,\n",
    "                    train_quantization_layer=True, print_result=False,\n",
    "                    add_noise=add_noise, device=device)\n",
    "\n",
    "        val_loss = eval_val(model=model,\n",
    "                val_dataloader=test_loader,\n",
    "                criterion=criterion, device = device)\n",
    "        \n",
    "        random_search_losses.append(best_val_loss)\n",
    " \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Architecture': hyperparameter_dict['architecture'],\n",
    "        'Loss': random_search_losses,\n",
    "        'Weight Decay': hyperparameter_dict['weight_decay'],\n",
    "        'Learning Rate': hyperparameter_dict['learning_rate'],\n",
    "        'Num Epochs': hyperparameter_dict['num_epochs'],\n",
    "        'Add Noise': hyperparameter_dict['add_noise'],\n",
    "        'Decrease Factor': hyperparameter_dict['decrease_factor']\n",
    "    })\n",
    "    results_df = results_df.sort_values('Loss')  # Sort by loss ascending    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [1:31:50<00:00, 36.74s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df_soft_compression = random_search_soft_compression_threshold( n_bits = 8,\n",
    "                                              n_steps = 150,\n",
    "                                              optimize_dict=\n",
    "                                              {'weight_decay': [0, 0.0001],\n",
    "                                              'learning_rate': [0.001, 0.0001],\n",
    "                                              'add_noise': [False, True],\n",
    "                                              'neuron_combination': neuron_combinations,\n",
    "                                              'num_epochs': [30,50,70],\n",
    "                                              'decrease_factor': [0.001, 0.0001]},\n",
    "                                              device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Architecture",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight Decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Learning Rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Num Epochs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Add Noise",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Decrease Factor",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c615c79f-7453-41ba-bc57-3022434d6c46",
       "rows": [
        [
         "13",
         "[128, 128, 128, 128]",
         "0.22225132103149708",
         "0.0001",
         "0.0001",
         "70",
         "False",
         "0.001"
        ],
        [
         "70",
         "[256, 1024, 1024, 256]",
         "0.22284061851409764",
         "0.0001",
         "0.0001",
         "30",
         "False",
         "0.001"
        ],
        [
         "45",
         "[1024, 1024, 512, 128]",
         "0.22359224087916887",
         "0.0001",
         "0.0001",
         "50",
         "False",
         "0.0001"
        ],
        [
         "88",
         "[256, 512, 512, 512, 512]",
         "0.22475700378417968",
         "0.0",
         "0.0001",
         "30",
         "False",
         "0.0001"
        ],
        [
         "23",
         "[128, 512, 1024, 1024, 1024, 512]",
         "0.2248424284733259",
         "0.0001",
         "0.0001",
         "50",
         "False",
         "0.0001"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Num Epochs</th>\n",
       "      <th>Add Noise</th>\n",
       "      <th>Decrease Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[128, 128, 128, 128]</td>\n",
       "      <td>0.222251</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[256, 1024, 1024, 256]</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[1024, 1024, 512, 128]</td>\n",
       "      <td>0.223592</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[256, 512, 512, 512, 512]</td>\n",
       "      <td>0.224757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[128, 512, 1024, 1024, 1024, 512]</td>\n",
       "      <td>0.224842</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Architecture      Loss  Weight Decay  Learning Rate  \\\n",
       "13               [128, 128, 128, 128]  0.222251        0.0001         0.0001   \n",
       "70             [256, 1024, 1024, 256]  0.222841        0.0001         0.0001   \n",
       "45             [1024, 1024, 512, 128]  0.223592        0.0001         0.0001   \n",
       "88          [256, 512, 512, 512, 512]  0.224757        0.0000         0.0001   \n",
       "23  [128, 512, 1024, 1024, 1024, 512]  0.224842        0.0001         0.0001   \n",
       "\n",
       "    Num Epochs  Add Noise  Decrease Factor  \n",
       "13          70      False           0.0010  \n",
       "70          30      False           0.0010  \n",
       "45          50      False           0.0001  \n",
       "88          30      False           0.0001  \n",
       "23          50      False           0.0001  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_soft_compression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_soft_compression.to_csv(f'results/{dataset}/random_search_results_soft_quantization_compression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out single architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 8\n",
    "n_bits = 4\n",
    "n_thresholds_per_feature = (2**n_bits-1)\n",
    "n_thresholds = num_features*n_thresholds_per_feature\n",
    "architecture = [n_thresholds,256,256,256,1]\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 70\n",
    "device = 'cuda'\n",
    "decrease_factor = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120, 256, 256, 256, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [19:54<00:00, 59.74s/it] \n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "for f in tqdm(range(20)):\n",
    "    thresholds = get_quantization_thresholds(train_loader, n_bits)\n",
    "    quantization_model = CompressionLayer(a_init = thresholds.flatten(), a_index = torch.repeat_interleave(torch.arange(num_features),n_thresholds_per_feature), tau = 1)\n",
    "    # CompressionLayer(num_features = thresholds.shape[0], num_thresholds_per_feature=thresholds.shape[1],tau = 1)\n",
    "    # quantization_model.set_thresholds(thresholds)\n",
    "    mlp = MultiLayerPerceptron(architecture)\n",
    "    model = nn.Sequential(\n",
    "        quantization_model,\n",
    "        mlp\n",
    "    )\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val_loss = train_model(model, num_epochs=num_epochs,\n",
    "                train_loader=train_loader, test_loader=test_loader, decrease_factor=decrease_factor,\n",
    "                optimizer=optimizer, criterion=criterion, has_quantization_layer=True,\n",
    "                train_quantization_layer=True, print_result=False,\n",
    "                add_noise=False, device=device)\n",
    "\n",
    "    val_loss = eval_val(model=model,\n",
    "            val_dataloader=test_loader,\n",
    "            criterion=criterion, device = device)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7eff90048260>,\n",
       "  <matplotlib.lines.Line2D at 0x7eff90049910>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7eff90049730>,\n",
       "  <matplotlib.lines.Line2D at 0x7eff90049640>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7eff90048650>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7eff9004a120>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7eff9004a7b0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Losses of soft layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27012983445937816,\n",
       " 0.2648538202047348,\n",
       " 0.2782393808548267,\n",
       " 0.26741580023215367,\n",
       " 0.26477311436946577,\n",
       " 0.25757721330110844,\n",
       " 0.2679829003719183,\n",
       " 0.26796831007187183,\n",
       " 0.2687665666525181,\n",
       " 0.25583835656826315,\n",
       " 0.2607624753163411,\n",
       " 0.2715140537573741,\n",
       " 0.27500283328386455,\n",
       " 0.2553736108999986,\n",
       " 0.2647632332948538,\n",
       " 0.26911976784467695,\n",
       " 0.2687500990354098,\n",
       " 0.27216559396340295,\n",
       " 0.2614028045764336,\n",
       " 0.2664514261942643]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation Losses of soft layers')\n",
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 120])\n",
      "torch.Size([65, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(65,8).to(device)\n",
    "quant_output = quantization_model(input)\n",
    "print(quant_output.shape)\n",
    "output = mlp(quant_output)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
